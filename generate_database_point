#!/usr/bin/env python3

# Generates a database of segments from one or more input files
import netCDF4
import numpy as np
import sys
import argparse
import calendar
import datetime
import time


def main():
   parser = argparse.ArgumentParser(description='Creates point database from NetCDF files')
   parser.add_argument('files', help='NetCDF files', nargs="+")
   parser.add_argument('-o', type=str, help="Output file", dest="ofile", required=True)
   parser.add_argument('-m', type=parse_ints, default=range(0,7), help="Use these ensemble members", dest="members")
   parser.add_argument('--debug', help='Show debug info', action="store_true")
   parser.add_argument('-i', default=[], help='Index files', nargs="*", dest="index_filenames")
   parser.add_argument('-dt', type=int, default=6, choices=[6, 24], help='Length of times in hours (6 or 24)', dest="dt")
   parser.add_argument('-d', type=int, default=15, help='How many days long should segments be?', dest="segment_length")
   parser.add_argument('-s', help='Sample file with grid', dest="sample_filename")
   parser.add_argument('-c', help='Smart chunking', dest="chunking", action="store_true")
   parser.add_argument('-p', help='Points file', dest="pfilename", required=True)
   # parser.add_argument('--progress', help='Show progress bar', action="store_true")

   if len(sys.argv) == 1:
      parser.print_help()
      sys.exit(1)

   args = parser.parse_args()

   # Which variables to output
   vars = ["air_temperature_2m", "precipitation_amount_acc", "sea_level_pressure", "cloud_area_fraction", "x_wind_10m", "y_wind_10m",
           "integral_of_surface_downwelling_shortwave_flux_in_air_wrt_time", "dew_point_temperature_2m"]
   units = ["K", "kg/m^2", "Pa", "1", "m/s", "m/s", "W s/m^2", "K"]
   func = [np.mean, np.sum, np.mean, np.mean, np.mean, np.mean, np.mean, np.mean]
   names = [var for var in vars]
   deacc = [False for var in vars]

   indices = dict()
   for filename in args.index_filenames:
      name = filename.split('/')[-1].split('.')[0]
      indices[name] = parse_indexfile(filename)
      vars += [name]
      units += ["1"]
      func += [np.mean]

   values = dict()
   points = read_points_file(args.pfilename)

   D = len(args.files) # Number of dates
   O = int(24 * args.segment_length / args.dt) + 1 # Number of leadtimes
   E = len(args.members) # Number of ensemble members
   G = len(points)

   # Calculate number of valid files
   valid_files = list()
   print("Number of possible files: %d" % D)
   for d in range(0, D):
      ifile = netCDF4.Dataset(args.files[d], 'r')
      print("%d %s" % (d, args.files[d]))
      if len(ifile.variables["time"][:]) >= 41 and "ensemble_member" in ifile.dimensions:
         valid_files += [args.files[d]]
      else:
         print("Invalid file: %s" % args.files[d])
      ifile.close()
   num_valid_files = len(valid_files)


   """
   Set up file
   """
   ofile = netCDF4.Dataset(args.ofile, 'w', zlib=True)#, format="NETCDF3_CLASSIC")
   ofile.createDimension("time")
   ofile.createDimension("lead_time", O)
   ofile.createDimension("ensemble_member", E)
   ofile.createDimension("grid_point", G)

   vVars = dict()
   vTime = ofile.createVariable("time", "i4", ("time"))
   vLeadTime = ofile.createVariable("lead_time", "i4", ("lead_time"))
   vLeadTime.units = "hours"
   vLeadTime[:] = np.arange(0, args.segment_length*24 + 6, args.dt)
   vLatitude = ofile.createVariable("latitude", "f4", ("grid_point"))
   vLongitude = ofile.createVariable("longitude", "f4", ("grid_point"))
   if "x" in points[0] and "y" in points[0]:
       vX = ofile.createVariable("x", "f4", ("grid_point"))
       vX.units = "m"
       vX.standard_name = "projection_x_coordinate"
       vY = ofile.createVariable("y", "f4", ("grid_point"))
       vY.units = "m"
       vY.standard_name = "projection_y_coordinate"
       ox = [point["x"] for point in points]
       oy = [point["y"] for point in points]
       vX[:] = ox
       vY[:] = oy

   vLongitude.long_name = "longitude"
   vLongitude.units = "degrees_east"
   vLatitude.long_name = "latitude"
   vLatitude.units = "degrees_north"

   vAltitude = ofile.createVariable("altitude", "f4", ("grid_point"))
   vAltitude.units = "m"
   vAltitude.long_name = "altitude"

   vTime.long_name = "time"
   vTime.standard_name = "time"
   vTime.units = "seconds since 1970-01-01 00:00:00 +00:00"

   olats = [point["lat"] for point in points]
   olons = [point["lon"] for point in points]
   vLatitude[:] = olats
   vLongitude[:] = olons

   chunksizes = None
   if args.chunking:
      chunksizes = [1,1,1,Y,X]
   for v in range(0, len(vars)):
      var = names[v]
      if args.debug:
         print("Defining variable %s" % var)
      vVars[var] = ofile.createVariable(var, "f4", ("time", "lead_time", "ensemble_member", "grid_point"), zlib=True, chunksizes=chunksizes)
      vVars[var].units = units[v]

   times = np.nan*np.zeros(num_valid_files, int)

   """
   Determine grid points
   """
   sample = netCDF4.Dataset(args.sample_filename, 'r')
   ilats = sample.variables["latitude"][:]
   ilons = sample.variables["longitude"][:]
   Ix = list()
   Iy = list()
   for point in points:
      currIx = np.argmin(np.abs(ilons - point["lon"]))
      currIy = np.argmin(np.abs(ilats - point["lat"]))
      Ix += [currIx]
      Iy += [currIy]

   """
   Read altitudes from sample file
   """
   if "altitude" in sample.variables:
      alts = sample.variables["altitude"][:]
   elif "surface_geopotential" in sample.variables:
      alts = sample.variables["surface_geopotential"][:] / 9.81
      if len(alts.shape) == 4:
         # Remove ensemble dimension
         alts = alts[0, 0, :, :]
      elif len(alts.shape) == 3:
         alts = alts[0, :, :]
   vAltitude[:] = alts[Iy, Ix]

   ofile.close()

   """
   Retrive data
   """
   for d in range(0, num_valid_files):
      print("Processing %s" % valid_files[d])
      time_file = time.time()
      ofile = netCDF4.Dataset(args.ofile, 'a', zlib=True)#, format="NETCDF3_CLASSIC")

      if args.debug:
         print("%d/%d" % (d+1, num_valid_files))
      ifile = netCDF4.Dataset(valid_files[d], 'r')
      times[d] = ifile.variables["time"][0]

      for var in vars:
         values[var] = np.nan*np.zeros([O, E, G], float)
      for index in indices:
         values[index] = np.nan*np.zeros([O, E, G], float)

      if args.dt == 24:
         print("ERROR: Cannot create 24h databases. Indexing not implemented")
         sys.exit(1)
         Ntime = O
         N = 4
      elif args.dt == 6:
         Ntime = O
         N = 1
      else:
         raise NotImplementedError

      for v in range(len(vars)):
         var = vars[v]
         var_output = names[v]
         if var not in indices:
            shape = ifile.variables[var].shape
            data = np.zeros([shape[0], len(args.members), len(Iy)])
            # data = ifile.variables[var][:, 0, args.members, Iy, Ix]
            time_data = time.time()
            q = ifile.variables[var][:, 0, args.members, :, :]
            q.shape
            for i in range(len(Iy)):
               data[:, :, i] = q[:, :, Iy[i], Ix[i]]
            # print("Time read data: %.2f s" % (time.time() - time_data))
            # Check that units match
            scale = 1
            units_input = None
            if hasattr(ifile.variables[var], 'units'):
               units_input = ifile.variables[var].units
            units_output = ofile.variables[var_output].units
            if units_input is not None and units_input != units_output:
               if args.debug:
                  print("Mismatch in units for %s: %s != %s" % (var, units_input, units_output))
               if units_input in ["Mg/m2", "Mg/m^2"] and units_output in ["mm", "kg/m^2", "kg/m2"]:
                  scale = 1000
                  if args.debug:
                     print("Multiplying by %g" % scale)
               else:
                  print("Cannot convert units from '%s' to '%s'!" % (units_input, units_output))
                  sys.exit(1)
               data *= scale
            for t in range(0, Ntime):
               # These indices do not work for 24 h, because ideally you want timesteps to start at (t+1) * N
               # and not t * N + 1

               I = range(t * N, (t + 1) * N)
               values[var][t, :, :] = func[v](data[I, :, :], axis=0)
               """
               Let's disable this for now, otherwise we miss the first timestep
               To reenable, change above to: O = int(24 * args.segment_length / args.dt) # Number of leadtimes
               
               if deacc[v]:
                  # Don't use the first timestep, because there is no precipitation
                  I = range(t * N, (t + 1) * N + 1)
                  values[var][t, :, :] = func[v](np.diff(data[I, :, :], axis=0), axis=0)
               else:
                  I = range(t * N + 1, (t + 1) * N + 1)
                  values[var][t, :, :] = func[v](data[I, :, :], axis=0)
               """
      for key,unixtime2value in indices.items():
         for t in range(0, Ntime):
            # Add 1 to use convention that the timepoint is at the end of the
            # interval
            unixtime = times[d] + (t + 1) * args.dt * 3600
            if unixtime in unixtime2value:
               values[key][t, :, :] = unixtime2value[unixtime]
      for v in range(0, len(vars)):
         # if args.debug:
         #    print("Writing variable %s" % var)
         var = vars[v]
         name = names[v]
         ofile.variables[name][d, :, :, :] = values[var]

      ofile.close()
      ifile.close()
      print("Time: %.2f s" % (time.time() - time_file))

   ofile = netCDF4.Dataset(args.ofile, 'a', zlib=True)#, format="NETCDF3_CLASSIC")
   ofile.variables["time"][:] = times

   # Add history string
   history_str = "%s Generated point database" % (datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S +00:00'))
   ofile.history = history_str

   ofile.close()
   sample.close()


def nc_convert_to_missing(data):
   nc_missing = netCDF4.default_fillvals["f4"]
   data[np.isnan(data)] = nc_missing
   return data


def error(message):
   """ Write error message to console and abort """
   print("\033[1;31mError: " + message + "\033[0m")
   sys.exit(1)


def warning(message):
   """ Write a warning message to console """
   print("\033[1;33mWarning: " + message + "\033[0m")


def parse_ints(numbers, is_date=False):
   ints = parse_numbers(numbers, is_date)
   return [int(x) for x in ints]


def parse_numbers(numbers, is_date=False):
   """
   Parses numbers from an input string. Recognizes MATLAB syntax, such as:
   3              single numbers
   3,4,5          list of numbers
   3:5            number range
   3:2:12         number range with a step size of 2
   3,4:6,2:5:9,6  combinations

   Aborts if the number cannot be parsed. Expect round-off errors for values
   below about 1e-4.

   Arguments:
      numbers (str): String of numbers
      is_date (bool): True if values should be interpreted as YYYYMMDD

   Returns:
      list: parsed numbers
   """
   # Check if valid string
   if(any(char not in set('-01234567890.:,') for char in numbers)):
      error("Could not translate '" + numbers + "' into numbers")

   values = list()
   commaLists = numbers.split(',')
   for commaList in commaLists:
      colonList = commaList.split(':')
      if(len(colonList) == 1):
         values.append(float(colonList[0]))
      elif(len(colonList) <= 3):
         start = float(colonList[0])
         step = 1
         if(len(colonList) == 3):
            step = float(colonList[1])
         if step == 0:
            error("Could not parse '%s': Step cannot be 0." % (numbers))
         stepSign = step / abs(step)
         # arange does not include the end point:
         end = float(colonList[-1]) + stepSign * 0.0001
         if(is_date):
            date = min(start, end)
            curr = list()
            while date <= max(start, end):
               curr.append(date)
               date = get_date(date, step)
            values = values + list(curr)
         else:
            # Note: Values are rounded, to avoid problems with floating point
            # comparison for strings like 0.1:0.1:0.9
            values = values + list(np.round(np.arange(start, end, step), 7))
      else:
         error("Could not translate '" + numbers + "' into numbers")
      if(is_date):
         for i in range(0, len(values)):
            values[i] = int(values[i])
   return values


def unixtime_to_day_of_year(unixtime):
   return int(datetime.datetime.utcfromtimestamp(unixtime).strftime('%j'))


def parse_indexfile(index_filename, edges=None):
   """
   Read a climatology index file and return a unixtime:value dict

   Returns:
      dict: unixtime (in seconds) to index value dictionary
   """
   ifile = open(index_filename, 'r')
   index = dict()
   prev = 0
   for line in ifile:
      words = line.strip().split(' ')
      words = [word for word in words if word != ""]
      year = int(words[0])
      month = int(words[1])
      if len(words) == 4:
         days = [int(words[2])]
      else:
         r = calendar.monthrange(year,month)
         days = range(1, r[1]+1)
      if words[-1] == "NA":
         value = prev
      else:
         value = float(words[-1])
         prev = value
      if edges is None:
         I = value
      else:
         I = np.where(value > edges)[0][-1]

      for day in days:
         date = int("%04d%02d%02d" % (year, month, day))
         unixtime = wxgen.util.date_to_unixtime(date)
         index[unixtime] = I
   ifile.close()
   return index


def read_points_file(filename):
    points = list()
    file = open(filename, 'r')
    header = file.readline().strip().split(';')
    for line in file:
        words = line.strip().split(';')
        curr = dict()
        curr['lat'] = float(words[header.index('lat')])
        curr['lon'] = float(words[header.index('lon')])
        curr['x'] = float(words[header.index('x')])
        curr['y'] = float(words[header.index('y')])
        points += [curr]

    file.close()

    return points


if __name__ == '__main__':
       main()
